{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3d5a5d-ccd7-4cf5-bc63-fb0a75078498",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "This project focuses on building a recommender system that predicts user ratings for books based on their past interactions. By understanding user preferences, the system aims to suggest books that align with individual tastes, enhancing the reading experience through personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e784c-b5fd-4e6c-8cdf-375980a0a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f904929-9d06-4a3f-83be-b5eb5cb5e584",
   "metadata": {},
   "source": [
    "Let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe9ac8-59f0-4c65-9031-da0f0e2cc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from tqdm import tqdm  # For displaying progress bars during iterations\n",
    "\n",
    "import pandas as pd # For data manipulation and CSV file handling\n",
    "import numpy as np # For numerical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912d4c8-40e9-4dab-b61e-7258aae2fdf4",
   "metadata": {},
   "source": [
    "Before we start, we need to load the two files needed for the project:\n",
    "- `train.csv`: contains the user ratings for the books.\n",
    "- `test.csv`: contains the user-book pairs for which we need to predict a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc829c5c-822c-46ab-9fa5-93b07ad95002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training, test, and books data\n",
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "test_df = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b0b49-9730-4a40-b069-0778db232834",
   "metadata": {},
   "source": [
    "## Matrix Factorization Method\n",
    "This section is devoted to the implementation of matrix factorization with bias (SVD-like approach) method to predict the rating a user might give to a book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5519e47-eea9-431c-b4f8-af15276f761f",
   "metadata": {},
   "source": [
    "In the first step, we define a function to compute the Root Mean Squared Error (RMSE), a key metric for evaluating the accuracy of our model's predictions. The RMSE calculates the average squared difference between the predicted and actual values, followed by taking the square root. We will use this function to evaluate the model's performance during hyperparameter tuning and on the final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f6223-8ac8-482d-900d-2e1a5e16fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the comutation of RMSE \n",
    "def compute_rmse(actual, predicted):\n",
    "    return np.sqrt(np.mean((actual - predicted) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d23d0-d821-4369-b534-399526b3f515",
   "metadata": {},
   "source": [
    "The next step is to divide the training dataset into two subsets: train_set and val_set. The train_set is used for training the model, while the val_set is reserved for validation during hyperparameter tuning. This split ensures that the evaluation of model performance is done on unseen data, preventing overfitting and enabling us to select the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f101f-a5f0-446e-8863-1aa2f1464129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets\n",
    "train_set, val_set = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f585896-0c4a-4f47-a363-fe7958ea72ad",
   "metadata": {},
   "source": [
    "We then define the grid search function, which systematically tests various combinations of hyperparameters (latent dimensions, learning rates, and regularization terms). For each combination, the model is trained on the train_set and evaluated on the val_set using RMSE. The best hyperparameters, which minimize RMSE on the validation set, are saved for training the final model. This process ensures that our model is both accurate and generalizes well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03967329-da95-4284-8152-3f8e8db2f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for performing grid search for hyperparameter tuning.\n",
    "def grid_search(train_set, val_set, latent_dims, learning_rates, reg_params, n_epochs=20):\n",
    "    print(\"Starting grid search...\")\n",
    "    best_params = None  # To store the best combination of hyperparameters\n",
    "    best_rmse = float('inf')  # Initialize the best RMSE to infinity\n",
    "    results = []  # List to store the results for each combination\n",
    "\n",
    "    # Iterate through all combinations of latent dimensions, learning rates, and regularization parameters\n",
    "    for latent_dim in latent_dims:\n",
    "        for learning_rate in learning_rates:\n",
    "            for reg_param in reg_params:\n",
    "                print(f\"Testing params: Latent Dim: {latent_dim}, Learning Rate: {learning_rate}, Regularization: {reg_param}\")\n",
    "\n",
    "                # Map user and book IDs to numerical indices for matrix operations\n",
    "                user_to_index = {user_id: idx for idx, user_id in enumerate(train_set['user_id'].unique())}\n",
    "                book_to_index = {book_id: idx for idx, book_id in enumerate(train_set['book_id'].unique())}\n",
    "\n",
    "                n_users = len(user_to_index)  # Total number of unique users\n",
    "                n_items = len(book_to_index)  # Total number of unique books\n",
    "\n",
    "                # Initialize latent factor matrices (P, Q) and biases (b_u, b_i) with small random values\n",
    "                P = np.random.normal(scale=0.01, size=(n_users, latent_dim))  # User latent factors\n",
    "                Q = np.random.normal(scale=0.01, size=(n_items, latent_dim))  # Book latent factors\n",
    "                mu = train_set['rating'].mean()  # Global mean of ratings\n",
    "                b_u = np.zeros(n_users)  # User biases\n",
    "                b_i = np.zeros(n_items)  # Book biases\n",
    "\n",
    "                # Training loop for the current combination of hyperparameters\n",
    "                for epoch in range(n_epochs):\n",
    "                    for _, row in train_set.iterrows():\n",
    "                        user_idx = user_to_index.get(row['user_id'])  # User index\n",
    "                        book_idx = book_to_index.get(row['book_id'])  # Book index\n",
    "                        rating = row['rating']  # Actual rating\n",
    "\n",
    "                        # Skip if user or book is not in the mapping\n",
    "                        if user_idx is None or book_idx is None:\n",
    "                            continue\n",
    "\n",
    "                        # Predicted rating using the model\n",
    "                        pred_rating = mu + b_u[user_idx] + b_i[book_idx] + np.dot(P[user_idx], Q[book_idx])\n",
    "\n",
    "                        # Compute the error between the actual and predicted ratings\n",
    "                        error = rating - pred_rating\n",
    "\n",
    "                        # Update biases and latent factors using gradient descent\n",
    "                        b_u[user_idx] += learning_rate * (error - reg_param * b_u[user_idx])\n",
    "                        b_i[book_idx] += learning_rate * (error - reg_param * b_i[book_idx])\n",
    "                        P[user_idx] += learning_rate * (error * Q[book_idx] - reg_param * P[user_idx])\n",
    "                        Q[book_idx] += learning_rate * (error * P[user_idx] - reg_param * Q[book_idx])\n",
    "\n",
    "                # Evaluate the model on the validation set\n",
    "                val_actual = []  # List of actual ratings in the validation set\n",
    "                val_predicted = []  # List of predicted ratings in the validation set\n",
    "\n",
    "                for _, row in val_set.iterrows():\n",
    "                    user_idx = user_to_index.get(row['user_id'])\n",
    "                    book_idx = book_to_index.get(row['book_id'])\n",
    "                    if user_idx is not None and book_idx is not None:\n",
    "                        # Predict rating using the model\n",
    "                        pred_rating = mu + b_u[user_idx] + b_i[book_idx] + np.dot(P[user_idx], Q[book_idx])\n",
    "                    else:\n",
    "                        # Fallback to global mean if user or book is not in the mapping\n",
    "                        pred_rating = mu  \n",
    "\n",
    "                    val_actual.append(row['rating'])\n",
    "                    val_predicted.append(pred_rating)\n",
    "\n",
    "                # Compute RMSE for the validation set\n",
    "                rmse = compute_rmse(np.array(val_actual), np.array(val_predicted))\n",
    "                print(f\"  Params RMSE: {rmse:.4f}\")\n",
    "                results.append((latent_dim, learning_rate, reg_param, rmse))  # Store results\n",
    "\n",
    "                # Update best parameters if current RMSE is the lowest\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = (latent_dim, learning_rate, reg_param)\n",
    "\n",
    "    # Print the best RMSE and corresponding hyperparameters\n",
    "    print(f\"Best RMSE: {best_rmse}\")\n",
    "    print(f\"Best Parameters: Latent Dim: {best_params[0]}, Learning Rate: {best_params[1]}, Regularization: {best_params[2]}\")\n",
    "    return best_params, results  # Return the best parameters and all results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c84541-0657-40a6-8d95-03dfe97ee73c",
   "metadata": {},
   "source": [
    "Using the best hyperparameters obtained from the grid search, we train the final model on the entire training dataset. The following function initializes the latent factors (user and item embeddings) and biases, and iteratively updates them using the chosen hyperparameters over multiple epochs. The objective is to minimize the prediction error by fine-tuning the model parameters. Once the training is complete, the function generates predictions for the test set. For each user-item pair in the test set, it calculates a predicted rating based on the trained model. If a user or item is not found in the training data, the function defaults to the global average rating. Finally, the predictions are saved as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fce3e-a6c6-4bff-8dec-a3cdeff8f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for trainning the model using the best parameters and predict ratings on the test set\n",
    "def train_and_predict(train_df, test_df, best_params, n_epochs=20):\n",
    "    # Unpack the best parameters obtained from grid search\n",
    "    latent_dim, learning_rate, reg_param = best_params\n",
    "    print(f\"Training final model with best params: Latent Dim: {latent_dim}, Learning Rate: {learning_rate}, Regularization: {reg_param}\")\n",
    "\n",
    "    # Map user and book IDs to numerical indices\n",
    "    user_to_index = {user_id: idx for idx, user_id in enumerate(train_df['user_id'].unique())}\n",
    "    book_to_index = {book_id: idx for idx, book_id in enumerate(train_df['book_id'].unique())}\n",
    "\n",
    "    # Number of unique users and books\n",
    "    n_users = len(user_to_index)\n",
    "    n_items = len(book_to_index)\n",
    "\n",
    "    # Initialize latent factor matrices for users (P) and books (Q) and biases\n",
    "    P = np.random.normal(scale=0.01, size=(n_users, latent_dim))  # User latent factors\n",
    "    Q = np.random.normal(scale=0.01, size=(n_items, latent_dim))  # Book latent factors\n",
    "    mu = train_df['rating'].mean()  # Global mean rating\n",
    "    b_u = np.zeros(n_users)  # User biases\n",
    "    b_i = np.zeros(n_items)  # Book biases\n",
    "\n",
    "    # Training loop: iterate over epochs to optimize the model\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0  # Track the cumulative loss for the epoch\n",
    "        for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "            user_idx = user_to_index.get(row['user_id'])  # Map user ID to index\n",
    "            book_idx = book_to_index.get(row['book_id'])  # Map book ID to index\n",
    "            rating = row['rating']  # Actual rating\n",
    "\n",
    "            # Skip if user or book is not in the training data\n",
    "            if user_idx is None or book_idx is None:\n",
    "                continue\n",
    "\n",
    "            # Predict the rating using the model\n",
    "            pred_rating = mu + b_u[user_idx] + b_i[book_idx] + np.dot(P[user_idx], Q[book_idx])\n",
    "\n",
    "            # Compute the error between actual and predicted ratings\n",
    "            error = rating - pred_rating\n",
    "\n",
    "            # Accumulate the squared error for loss tracking\n",
    "            total_loss += error**2\n",
    "\n",
    "            # Update biases and latent factors using gradient descent\n",
    "            b_u[user_idx] += learning_rate * (error - reg_param * b_u[user_idx])  # Update user bias\n",
    "            b_i[book_idx] += learning_rate * (error - reg_param * b_i[book_idx])  # Update book bias\n",
    "            P[user_idx] += learning_rate * (error * Q[book_idx] - reg_param * P[user_idx])  # Update user latent factors\n",
    "            Q[book_idx] += learning_rate * (error * P[user_idx] - reg_param * Q[book_idx])  # Update book latent factors\n",
    "\n",
    "        # Print the cumulative loss after each epoch\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Prediction: Generate predictions for the test set\n",
    "    predictions = []\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Predicting\"):\n",
    "        user_idx = user_to_index.get(row['user_id'])  # Map user ID to index\n",
    "        book_idx = book_to_index.get(row['book_id'])  # Map book ID to index\n",
    "\n",
    "        # Predict the rating for user-book pair or fallback to the global mean\n",
    "        if user_idx is not None and book_idx is not None:\n",
    "            pred_rating = mu + b_u[user_idx] + b_i[book_idx] + np.dot(P[user_idx], Q[book_idx])\n",
    "        else:\n",
    "            pred_rating = mu  # Fallback to global mean rating if user or book is unknown\n",
    "\n",
    "        # Append the prediction to the results\n",
    "        predictions.append({'id': row['id'], 'rating': pred_rating})\n",
    "\n",
    "    # Save predictions to a CSV file\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    predictions_df.to_csv(\"svd_predictions.csv\", index=False)  # Save predictions for submission or evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02063d-0b2b-4594-bf5d-44ba0daa0bf0",
   "metadata": {},
   "source": [
    "Here is the search space for the hyperparameters that will be tested during the grid search. The key hyperparameters include:\n",
    "- latent_dims: The number of latent dimensions for user and item embeddings, which control the complexity of the model.\n",
    "- learning_rates: The step sizes for updating the model parameters during training.\n",
    "- reg_params: Regularization parameters to prevent overfitting by penalizing large values in the model's parameters.\n",
    "\n",
    "Using the grid search function, we evaluate every combination of these hyperparameters on the training and validation sets. The goal is to identify the set of parameters that minimizes the validation error (measured by RMSE).\n",
    "\n",
    "The best parameters are then stored for training the final model, ensuring it is both accurate and generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a28ca7-bf9b-49b3-a388-d91f9b6d6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to test\n",
    "latent_dims = [25, 50, 75]\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "reg_params = [0.01, 0.05, 0.1, 0.02]\n",
    "\n",
    "# Perform grid search\n",
    "best_params, grid_results = grid_search(train_set, val_set, latent_dims, learning_rates, reg_params, n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4145f8-fae8-4d4f-b354-e393bc3d1156",
   "metadata": {},
   "source": [
    "Finally, we train the model using the best hyperparameters identified during the grid search, in order to predict ratings for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a02c4-4fff-4c10-9ce3-28c94b633bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model and predict\n",
    "train_and_predict(train_df, test_df, best_params, n_epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
