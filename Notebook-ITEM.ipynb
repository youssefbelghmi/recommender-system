{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3d5a5d-ccd7-4cf5-bc63-fb0a75078498",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "This project focuses on building a recommender system that predicts user ratings for books based on their past interactions. By understanding user preferences, the system aims to suggest books that align with individual tastes, enhancing the reading experience through personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59febc1-517c-40f9-ac24-c7272255fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f904929-9d06-4a3f-83be-b5eb5cb5e584",
   "metadata": {},
   "source": [
    "Let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3be70-93c6-465d-be5c-481d90aab4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances  # For calculating cosine similarity\n",
    "\n",
    "import pandas as pd  # For data manipulation and CSV file handling\n",
    "import numpy as np  # For numerical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912d4c8-40e9-4dab-b61e-7258aae2fdf4",
   "metadata": {},
   "source": [
    "Before we start, we need to load the two files needed for the project:\n",
    "- `train.csv`: contains the user ratings for the books.\n",
    "- `test.csv`: contains the user-book pairs for which we need to predict a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef686cbf-c848-438a-a76c-7256c42700c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training, test, and books data\n",
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "test_df = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b0b49-9730-4a40-b069-0778db232834",
   "metadata": {},
   "source": [
    "## Item-Based Collaborative Filtering Method\n",
    "This section is devoted to the implementation of an item-based collaborative filtering method to predict the rating a user might give to a book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005099f0-838f-405e-b56d-e2811a0c67d4",
   "metadata": {},
   "source": [
    "First of all, we need to build a user-item matrix by first mapping each unique user_id and book_id to a unique index, allowing us to easily locate users and books within the matrix. By initializing the matrix with zeros and populating it with ratings from the training data, where each row represents a user and each column represents a book, we create a structured format suitable for collaborative filtering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4170018-d34d-4d75-a96f-fed764db92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique user and book IDs\n",
    "users = train_df['user_id'].unique()\n",
    "books = train_df['book_id'].unique()\n",
    "\n",
    "# Create mappings for users and books to indices\n",
    "user_to_index = {user: i for i, user in enumerate(users)}\n",
    "book_to_index = {book: i for i, book in enumerate(books)}\n",
    "\n",
    "# Initialize the user-item matrix with zeros\n",
    "user_item_matrix = np.zeros((len(users), len(books)))\n",
    "\n",
    "# Populate the matrix with ratings from the training data\n",
    "for _, row in train_df.iterrows():\n",
    "    user_idx = user_to_index[row['user_id']]\n",
    "    book_idx = book_to_index[row['book_id']]\n",
    "    user_item_matrix[user_idx, book_idx] = row['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcc427-261c-4131-805f-cd598d159fae",
   "metadata": {},
   "source": [
    "To prepare for item-based collaborative filtering predictions, we calculate cosine similarity matrix. We calculate the similarity between books by analyzing user ratings, which requires transposing the training data so that books are compared directly. This similarity matrix help identify the closest matches, which are then used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb2bdc-2c41-4f5c-a9ba-59c1640b5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity matrix\n",
    "def calculate_cosine_similarity(user_item_matrix):\n",
    "    return 1 - pairwise_distances(user_item_matrix, metric='cosine')\n",
    "\n",
    "# Calculate item similarity using cosine similarity\n",
    "item_similarity = calculate_cosine_similarity(user_item_matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27301ad-7527-4899-99c3-b7b410e8b36c",
   "metadata": {},
   "source": [
    "The next step is to create a function to calculate the predicted ratings for a user-book pair. The function identifies “neighbors” and calculates the predicted rating as a weighted average of their contributions. This is done by multiplying the similarity score by the known rating and normalizing it using the sum of the absolute similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7ef81-9729-4e23-a9e6-3bd1a8714643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a rating for a given user-book pair using collaborative filtering.\n",
    "def calculate_prediction(user_idx, target_idx, similarity_matrix, data_matrix):\n",
    "    # Item-based filtering: Neighbors are other books rated by the same user\n",
    "    rated_items = np.where(data_matrix[user_idx, :] > 0)[0]  # Books rated by the target user\n",
    "    ratings = data_matrix[user_idx, :]  # Ratings by the user\n",
    "\n",
    "    numerator = 0  # Sum of weighted ratings\n",
    "    denominator = 0  # Sum of absolute similarity scores\n",
    "\n",
    "    # Iterate through rated items\n",
    "    for neighbor_idx in rated_items:\n",
    "        similarity = similarity_matrix[target_idx, neighbor_idx]  # Similarity between items\n",
    "        rating = data_matrix[user_idx, neighbor_idx]  # Rating given by the user for the neighbor item\n",
    "        numerator += similarity * rating\n",
    "        denominator += abs(similarity)\n",
    "\n",
    "    # Compute the predicted rating\n",
    "    if denominator > 0:\n",
    "        return numerator / denominator\n",
    "    elif np.any(ratings > 0):\n",
    "        # Default to the average of known ratings\n",
    "        return ratings[ratings > 0].mean()\n",
    "    else:\n",
    "        # If no neighbors exist, return a random rating between 0 and 5\n",
    "        return np.random.uniform(0.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339099f-8994-4e08-8ad3-a9e6ae499873",
   "metadata": {},
   "source": [
    "Next, in order to predict the desired grades, we need to create a function that iterates over each user-book pair in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5018609-88b5-443c-ae04-af4509aa55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict ratings for all user-book pairs in the test dataset.\n",
    "def predict_ratings(test_df, similarity_matrix, data_matrix):\n",
    "    # Initialize an empty dictionary to store predictions\n",
    "    predictions = {} \n",
    "\n",
    "    # Iterate over each row in the test dataset\n",
    "    for _, row in test_df.iterrows():\n",
    "        query_id = row['id']  # Unique identifier for the test pair\n",
    "        user_id = row['user_id']  # User ID for the current test pair\n",
    "        book_id = row['book_id']  # Book ID for the current test pair\n",
    "\n",
    "        # Skip the pair if the user or book is not in the training dataset\n",
    "        if user_id not in user_to_index or book_id not in book_to_index:\n",
    "            predictions[query_id] = None  # Assign a `None` value for out-of-scope pairs\n",
    "            continue\n",
    "\n",
    "        user_idx = user_to_index[user_id]  # Get the user index\n",
    "        book_idx = book_to_index[book_id]  # Get the book index\n",
    "\n",
    "        # Predict the rating using the appropriate filtering method\n",
    "        predicted_rating = calculate_prediction(\n",
    "            user_idx=user_idx,\n",
    "            target_idx=book_idx,  \n",
    "            similarity_matrix=similarity_matrix,\n",
    "            data_matrix=data_matrix,\n",
    "        )\n",
    "\n",
    "        predictions[query_id] = predicted_rating  # Store the predicted rating\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35570ed8-60bb-44c9-98cc-7a6ffd17feb1",
   "metadata": {},
   "source": [
    "Finally, we save predicted ratings into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dbe4b8-4048-4cf4-abe2-2b5d32457db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save predictions to a CSV file\n",
    "def save_predictions_to_csv(predictions, output_file):\n",
    "    # Convert the dictionary into a DataFrame and save it\n",
    "    predictions_df = pd.DataFrame(list(predictions.items()), columns=['id', 'rating'])\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Generate and save predictions for Item-Based Collaborative Filtering\n",
    "item_based_predictions = predict_ratings(test_df, item_similarity, user_item_matrix)\n",
    "save_predictions_to_csv(item_based_predictions, \"item_based_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
